---
environment:
  base_dir: "C:/00_dev/00_playground/04_TEACH/UNO/2025/clases/health_economics_challenge"
  data_dir: "./dataset"

experiment:
  restart: FALSE
  type: "HealthEconomics"
  tags: ["health", "economics", "challenge", "2025"]
  H1: "prediccion_gasto_bolsillo_ppp_2022"
  exp_dir: "./exp"
  experiment_label: "hf3_pred"
  experiment_code: "v_alumno"
  
feature_engineering:
  files:
    input:
      dentrada: ["dataset_desafio.csv"]
    output:
      # dsalida establecido dinamicamente
    fe_script: "01_FE_health_ALUMNO.R"

  const:
    # ========================================
    # !!!!! DECISIÓN ESTRATÉGICA !!!!!
    # ========================================
    # Variable objetivo: gasto de bolsillo per capita PPP
    origen_clase: "hf3_ppp_pc"
    clase: "clase"
    
    # orden_lead: ¿Cuántos años hacia el futuro predecimos?
    # Opciones: 1, 2, 3, 4
    # Si presente=2021 y orden_lead=1 → predice 2022
    # Si presente=2019 y orden_lead=3 → predice 2022
    orden_lead: ???  # ← COMPLETAR CON NÚMERO
    
    frollmean_n: 2
    reference_years_n: 3
    
    # presente: ¿Cuál es el último año CON DATOS que usamos?
    # Opciones: 2018, 2019, 2020, 2021
    # DECISIÓN CRÍTICA: ¿Usamos datos de COVID (2020-2021) o no?
    presente: ???  # ← COMPLETAR CON AÑO
    
    canaritos_year_start: 2000
    canaritos_year_end:  # Se calcula automáticamente
    canaritos_year_valid:  # Se calcula automáticamente
    
    # Campos clave para economía de la salud
    campos_sort: ["Country Code", "year"]
    campos_rsort: ["year", "Country Code"]
    campos_fijos: ["Country Name", "Country Code", "year", "region", "income", "hf3_ppp_pc","clase"]
    
    # Variables de control mínimas
    mincontrolset: ["region", "income", "year"]
    
    campos_lead: []
    campos_descartar: []
    
  param:
    dummiesNA: TRUE  # Crear dummies para valores faltantes
    
    corregir: "NO"
    variablesdrift: []
    
    # !!!!! IMPORTANTE !!!!!
    # variablesmanuales: ¿Ejecutar la función AgregarVariables() que ustedes completen?
    # TRUE = ejecuta su feature engineering personalizado
    # FALSE = solo usa las variables automáticas (útil para comparar)
    variablesmanuales: TRUE
    
    acumulavars: FALSE
    
    # Lags: Valores de años anteriores
    # lag=1 → año pasado, lag=2 → hace 2 años, etc.
    # delta=TRUE → también crea la diferencia (cambio respecto a ese lag)
    lags: 
      correr: [TRUE, TRUE, TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE]
      lag: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
      delta: [TRUE, TRUE, TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE]
      canaritos: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

    # Tendencias y estadísticas móviles en ventanas temporales (años)
    # ventana=2 → usa los últimos 2 años
    # tendencia → pendiente de regresión lineal
    # minimo/maximo → valores extremos en la ventana
    # promedio → media
    # ratioavg/ratiomax → valor actual dividido por promedio (o máximo)
    tendenciaYmuchomas:
      correr: [TRUE, TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE]
      ventana: [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 20]
      tendencia: [TRUE, TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE]
      minimo: [TRUE, TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE]
      maximo: [TRUE, TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE]
      promedio: [TRUE, TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE]
      ratioavg: [TRUE, TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE]
      ratiomax: [TRUE, TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE]
      canaritos: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
      
    # NO USAR leads (causaría data leakage)
    leads:
      correr: [FALSE, FALSE, FALSE, FALSE, FALSE, FALSE]
      lead: [1, 2, 3, 4, 5, 6]
    
    # Otras transformaciones automáticas
    tony: FALSE
    rankeador: TRUE  # Crea rankings (0-1) por año
    
    canaritos_final: 0.0  # Sin filtrado final de variables

training_strategy:
  const:
    secciones: ["present", "train", "validate", "test", "train_final"]
    clase: "clase"
    periodo: "year"
    presente: []  # Se establece automáticamente
    campos_sort: ["Country Code", "year"]
    TS_train_desde: [2000]
    
  param:
    semilla: 102191

    # ========================================
    # !!!!! DECISIÓN ESTRATÉGICA !!!!!
    # ========================================
    # excluir: ¿Qué años ELIMINAR del entrenamiento?
    # Opciones:
    #   [] = usar todos los años disponibles
    #   [2020, 2021] = eliminar años COVID
    #   [2020] = eliminar solo 2020
    #
    # IMPORTANTE: Esta decisión va de la mano con "presente"
    # Ejemplos de configuraciones:
    #   A) presente=2021, excluir=[] → Usas TODO incluyendo COVID
    #   B) presente=2021, excluir=[2020,2021] → Predices desde 2021 pero NO entrenas con COVID
    #   C) presente=2019, excluir=[] → No usas datos post-2019 en ningún lado
    #   D) presente=2020, excluir=[2020] → Usas hasta 2020 pero sin entrenar con 2020

    # Datos actuales sin target (para predicción final)
    present:
      periodos: []
      rango:
        desde:
        hasta:
      excluir: []
      undersampling: []

    # Entrenamiento
    train:
      periodos: []
      rango:
        desde: 2000
        hasta:  # Se calcula automáticamente
      excluir: ???  # ← COMPLETAR: [] o [2020,2021] u otra combinación
      undersampling: []

    # Validación
    validate:
      periodos: []
      rango:
        desde:
        hasta:
      excluir: ???  # ← COMPLETAR: [] o [2020,2021] u otra combinación
      undersampling: []

    # Test
    test:
      periodos: []
      rango:
        desde:
        hasta:
      excluir: ???  # ← COMPLETAR: [] o [2020,2021] u otra combinación
      undersampling: []

    # Entrenamiento final (todo el período)
    train_final:
      periodos: []
      rango:
        desde: 2000
        hasta:  # Se calcula automáticamente
      excluir: ???  # ← COMPLETAR: [] o [2020,2021] u otra combinación
      undersampling: []
    
  files:
    input:
      dentrada: []
    output:
      present_data: "TS_present_data.csv.gz"
      train_strategy: "TS_train_strategy.csv.gz"
      train_final: "TS_train_final.csv.gz"
      control: "control.txt"
    ts_script: "02_TS_health.R"

hyperparameter_tuning:
  param:
    algoritmo: "lightgbm"
    semilla: 999983
    crossvalidation: FALSE
    crossvalidation_folds: 5
    validate: TRUE

    clase_train_POS: "clase"
    clase_validate_POS: "clase"
    clase_test_POS: "clase"

    # ========================================
    # PARÁMETROS LIGHTGBM
    # ========================================
    # Estos son los rangos de búsqueda para la optimización bayesiana
    # Formato: [valor_mínimo, valor_máximo] para continuos
    #          [valor_mínimo, valor_máximo, 1] para enteros
    #
    # NO ES NECESARIO modificar estos rangos salvo que tengan
    # experiencia avanzada con LightGBM
    lightgbm:
      # Learning rate: qué tan rápido aprende el modelo
      # Valores bajos (0.01-0.05) → aprende lento pero mejor
      # Valores altos (0.1-0.2) → aprende rápido pero puede overfittear
      learning_rate: [0.01, 0.2]
      
      # Feature fraction: qué proporción de variables usar en cada árbol
      # 0.3 = usa 30% de variables, 0.9 = usa 90%
      # Valores bajos previenen overfitting
      feature_fraction: [0.3, 0.9]
      
      # Num leaves: cuántas hojas por árbol (complejidad del modelo)
      # Valores bajos (10-50) → modelo simple
      # Valores altos (500-1500) → modelo complejo
      # Éste es el parámetro que afecta más el consumo de memoria. Valores más altos durante una iteración tienen mayor consumo de memoria. Si se supera el límite de memoria, se produce un error. Por lo tanto, pueden necesitar reducir este valor máximo, si se está enfrentando a problemas de memoria.
      num_leaves: [10, 1500, 1]
      
      # Min data in leaf: mínimo de observaciones por hoja
      # Normalmente esto debe setearse a la mitad del total de registros en el conjunto de entrenamiento.
      min_data_in_leaf: [5, 100, 1]
      
      # Regularización L1 y L2. Dejar así.
      lambda_l1: [0, 5]
      lambda_l2: [0, 10]
      min_gain_to_split: 0
      
      # Bagging: submuestreo de datos
      bagging_fraction: [0.6, 1.0]
      
      pos_bagging_fraction: 1.0
      neg_bagging_fraction: 1.0
      
      # Otros parámetros (fijos)
      max_depth: -1  # Sin límite de profundidad
      max_bin: 255
      
      seed: 999983
      extra_trees: FALSE
      
      # Parámetros para boosting tipo "dart" (no usado por defecto)
      drop_rate: 0.1
      max_drop: 50
      skip_drop: 0.5
      
      # Métrica a optimizar (RMSE = Root Mean Squared Error)
      metric: "rmse"
      first_metric_only: TRUE
      
      # Configuración del problema (regression)
      objective: "regression"
      boost_from_average: TRUE
      force_row_wise: TRUE
      feature_pre_filter: FALSE
      boosting: "gbdt"  # Gradient Boosting Decision Tree
      num_threads: 0  # Usar todos los threads disponibles
      verbosity: -100
      verbose: -100

  # Optimización Bayesiana (mlrMBO)
    BO:
      # Iteraciones: cuántas configuraciones de hiperparámetros probar
      # Más iteraciones = mejor resultado pero más tiempo
      # 100 iteraciones ≈ 30-60 minutos (depende del hardware)
      iterations: 100
      
      noisy: TRUE
      minimize: TRUE  # Minimizar RMSE (menor es mejor)
      has.simple.signature: FALSE
      save.on.disk.at.time: 600  # Guardar cada 10 minutos

  files:
    input:
      dentrada: "TS_train_strategy.csv.gz"
      dweights: ""
    output:
      BOlog: "BO_log.txt"
      BObin: "BO_bin.Rdata"
      tb_importancia: "tb_importancia.txt"
      importancia: "impo_"
    ht_script: "03_HT_health.R"

  const:
    campo_clase: "clase"
    campo_periodo: "year"
